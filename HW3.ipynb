{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import collections\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822831a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\AppData\\Local\\Temp/ipykernel_97832/1351344004.py:4: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29733840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d02d680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Matthew\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96eb66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b09b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01364b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a7812ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76502c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1875d9eb910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) # Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6191ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n",
      "Device: cuda\n",
      "Device name: NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "#detecting the GPU \n",
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if gpu_avail:\n",
    "    print(\"Device name: \" + torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c2d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder\n",
    "DATASET_PATH = \"../Desktop/ML\"\n",
    "#setting the seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294590b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Data mean [0.49139968 0.48215841 0.44653091]\n",
      "Data std [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
    "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0,1,2))\n",
    "DATA_STD = (train_dataset.data / 255.0).std(axis=(0,1,2))\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04bb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c910914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            \n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8554a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "                                     ])\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "                                     ])\n",
    "\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "set_seed(42)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "set_seed(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48502cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "model = Net()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "\n",
    "\n",
    "model = Net().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2) \n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad767f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebbbc86091a4636a497c927eeabd62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 13:08:41.471312 Epoch 1, Training loss 2.273516862141101\n",
      "2022-03-29 13:11:25.055877 Epoch 10, Training loss 1.4325055325472797\n",
      "2022-03-29 13:15:05.856786 Epoch 20, Training loss 1.2439932571856724\n",
      "2022-03-29 13:19:06.880713 Epoch 30, Training loss 1.142515715540644\n",
      "2022-03-29 13:22:39.765654 Epoch 40, Training loss 1.0807891426942287\n",
      "2022-03-29 13:26:19.875471 Epoch 50, Training loss 1.0384035915391059\n",
      "2022-03-29 13:29:29.048677 Epoch 60, Training loss 1.0102278948509456\n",
      "2022-03-29 13:32:42.893782 Epoch 70, Training loss 0.9824230529983499\n",
      "2022-03-29 13:36:29.495652 Epoch 80, Training loss 0.963858820773937\n",
      "2022-03-29 13:39:50.431559 Epoch 90, Training loss 0.9437842117755162\n",
      "2022-03-29 13:42:49.623984 Epoch 100, Training loss 0.9308946175113363\n",
      "2022-03-29 13:45:47.963887 Epoch 110, Training loss 0.9162210081717228\n",
      "2022-03-29 13:48:48.668771 Epoch 120, Training loss 0.9048870745887104\n",
      "2022-03-29 13:51:53.833245 Epoch 130, Training loss 0.897735546626936\n",
      "2022-03-29 13:55:12.735863 Epoch 140, Training loss 0.8865952996107248\n",
      "2022-03-29 13:58:41.863589 Epoch 150, Training loss 0.8794097202455896\n",
      "2022-03-29 14:02:38.916007 Epoch 160, Training loss 0.8649730521049934\n",
      "2022-03-29 14:06:41.836355 Epoch 170, Training loss 0.8594304900563341\n",
      "2022-03-29 14:10:38.208882 Epoch 180, Training loss 0.8515863861793127\n",
      "2022-03-29 14:14:32.000700 Epoch 190, Training loss 0.8442122623791383\n",
      "2022-03-29 14:18:08.782944 Epoch 200, Training loss 0.8400546626487688\n",
      "2022-03-29 14:22:02.822200 Epoch 210, Training loss 0.8331808811239367\n",
      "2022-03-29 14:26:00.492960 Epoch 220, Training loss 0.8252719915830172\n",
      "2022-03-29 14:30:03.231171 Epoch 230, Training loss 0.82021612115735\n",
      "2022-03-29 14:34:17.320948 Epoch 240, Training loss 0.8186045633761632\n",
      "2022-03-29 14:38:17.760918 Epoch 250, Training loss 0.811680816177629\n",
      "2022-03-29 14:42:14.806328 Epoch 260, Training loss 0.8137914986691923\n",
      "2022-03-29 14:46:13.310296 Epoch 270, Training loss 0.8096846199443197\n",
      "2022-03-29 14:50:13.283434 Epoch 280, Training loss 0.8033499114873403\n",
      "2022-03-29 14:54:04.564611 Epoch 290, Training loss 0.7982420649623599\n",
      "2022-03-29 14:57:20.317883 Epoch 300, Training loss 0.7984618669391698\n",
      "Accuracy train: 0.73\n",
      "Accuracy val: 0.70\n"
     ]
    }
   ],
   "source": [
    "#Finally, training for 300 Epochs\n",
    "training_loop(  \n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f50a6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B, adding more layers\n",
    "class Net2Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * 4)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c2af9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net2Layers()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "\n",
    "\n",
    "model = Net2Layers().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2) \n",
    "loss_fn = nn.CrossEntropyLoss()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b183d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4cb28f8f5475791481212e255d09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:19:55.406099 Epoch 1, Training loss 2.2480272119201485\n",
      "2022-03-29 15:23:29.764595 Epoch 10, Training loss 1.4279922274103192\n",
      "2022-03-29 15:27:46.827025 Epoch 20, Training loss 1.2805870404610267\n",
      "2022-03-29 15:31:17.499342 Epoch 30, Training loss 1.1850827212347264\n",
      "2022-03-29 15:35:22.516037 Epoch 40, Training loss 1.1196661858137515\n",
      "2022-03-29 15:40:02.597008 Epoch 50, Training loss 1.0601725919633849\n",
      "2022-03-29 15:44:25.015122 Epoch 60, Training loss 1.017804021169657\n",
      "2022-03-29 15:48:24.022534 Epoch 70, Training loss 0.9918310010535085\n",
      "2022-03-29 15:52:22.826827 Epoch 80, Training loss 0.9684683979406655\n",
      "2022-03-29 15:56:43.597989 Epoch 90, Training loss 0.9422862385412907\n",
      "2022-03-29 16:01:02.186348 Epoch 100, Training loss 0.9197289113305572\n",
      "2022-03-29 16:05:02.505344 Epoch 110, Training loss 0.8988188792158056\n",
      "2022-03-29 16:09:13.763919 Epoch 120, Training loss 0.8855711062069972\n",
      "2022-03-29 16:13:40.838800 Epoch 130, Training loss 0.8754912889920748\n",
      "2022-03-29 16:17:36.003342 Epoch 140, Training loss 0.8630180523606108\n",
      "2022-03-29 16:21:30.948632 Epoch 150, Training loss 0.8438418381913775\n",
      "2022-03-29 16:25:25.609199 Epoch 160, Training loss 0.841234160963966\n",
      "2022-03-29 16:29:57.546583 Epoch 170, Training loss 0.8370881916111351\n",
      "2022-03-29 16:34:56.988275 Epoch 180, Training loss 0.8261533875411052\n",
      "2022-03-29 16:38:35.870933 Epoch 190, Training loss 0.8223153383303912\n",
      "2022-03-29 16:42:41.845910 Epoch 200, Training loss 0.8176807992139093\n",
      "2022-03-29 16:46:41.309397 Epoch 210, Training loss 0.8136559194988675\n",
      "2022-03-29 16:50:36.977501 Epoch 220, Training loss 0.805880646590154\n",
      "2022-03-29 16:55:11.521579 Epoch 230, Training loss 0.8028905986041425\n",
      "2022-03-29 16:59:39.520966 Epoch 240, Training loss 0.7989342520039985\n",
      "2022-03-29 17:03:27.174553 Epoch 250, Training loss 0.7990655516966795\n",
      "2022-03-29 17:06:48.778432 Epoch 260, Training loss 0.7956198413147886\n",
      "2022-03-29 17:10:08.493470 Epoch 270, Training loss 0.7860277660212286\n",
      "2022-03-29 17:13:30.185642 Epoch 280, Training loss 0.7831572844431951\n",
      "2022-03-29 17:16:52.304068 Epoch 290, Training loss 0.7857833277126323\n",
      "2022-03-29 17:20:14.346915 Epoch 300, Training loss 0.7832335496899748\n",
      "Accuracy train: 0.73\n",
      "Accuracy val: 0.70\n"
     ]
    }
   ],
   "source": [
    "#training \n",
    "training_loop(  \n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a86199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=False)\n",
    "        #torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = torch.relu(out)\n",
    "        return out + x #Skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80687c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a46e234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76010 [864, 32, 9216, 65536, 32, 320, 10]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet_10()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(sum(numel_list), numel_list)\n",
    "\n",
    "model = ResNet_10().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cfc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aed591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Part B\n",
    "#Weight Decay:\n",
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum()\n",
    "                          for p in model.parameters())  # <1>\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a279cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock_DO(nn.Module):\n",
    "    def __init__(self, n_chans, p):\n",
    "        super(ResBlock_DO, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p = p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.dropout(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "398a3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet10_DO(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10, p=0.3):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock_DO(n_chans=n_chans1, p=p)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16309992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResBlock_BN(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock_BN, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                              padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "916d136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76010 [864, 32, 9216, 65536, 32, 320, 10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet_10()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(sum(numel_list), numel_list)\n",
    "\n",
    "model = ResNet_10().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46143751",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop_l2reg(\n",
    "    n_epochs = 150,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5128898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76010 [864, 32, 9216, 65536, 32, 320, 10]\n"
     ]
    }
   ],
   "source": [
    "#Dropout Model:\n",
    "model = ResNet10_DO()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(sum(numel_list), numel_list)\n",
    "\n",
    "model = ResNet10_DO().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ee2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    n_epochs = 150,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dda74fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76074 [864, 32, 9216, 32, 32, 65536, 32, 320, 10]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet10_BN()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(sum(numel_list), numel_list)\n",
    "\n",
    "model = ResNet10_BN().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
