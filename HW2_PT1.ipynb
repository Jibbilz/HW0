{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a6d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37981f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.DataFrame(pd.read_csv('ML/Housing.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c77ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1820000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1767150</td>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1750000</td>\n",
       "      <td>3620</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1750000</td>\n",
       "      <td>2910</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1750000</td>\n",
       "      <td>3850</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0    13300000  7420         4          2        3      yes        no       no   \n",
       "1    12250000  8960         4          4        4      yes        no       no   \n",
       "2    12250000  9960         3          2        2      yes        no      yes   \n",
       "3    12215000  7500         4          2        2      yes        no      yes   \n",
       "4    11410000  7420         4          1        2      yes       yes      yes   \n",
       "..        ...   ...       ...        ...      ...      ...       ...      ...   \n",
       "540   1820000  3000         2          1        1      yes        no      yes   \n",
       "541   1767150  2400         3          1        1       no        no       no   \n",
       "542   1750000  3620         2          1        1      yes        no       no   \n",
       "543   1750000  2910         3          1        1       no        no       no   \n",
       "544   1750000  3850         3          1        2      yes        no       no   \n",
       "\n",
       "    hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0                no             yes        2      yes        furnished  \n",
       "1                no             yes        3       no        furnished  \n",
       "2                no              no        2      yes   semi-furnished  \n",
       "3                no             yes        3      yes        furnished  \n",
       "4                no             yes        2       no        furnished  \n",
       "..              ...             ...      ...      ...              ...  \n",
       "540              no              no        2       no      unfurnished  \n",
       "541              no              no        0       no   semi-furnished  \n",
       "542              no              no        0       no      unfurnished  \n",
       "543              no              no        0       no        furnished  \n",
       "544              no              no        0       no      unfurnished  \n",
       "\n",
       "[545 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d05b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
       "0         0                0                1        2         1   \n",
       "1         0                0                1        3         0   \n",
       "2         1                0                0        2         1   \n",
       "3         1                0                1        3         1   \n",
       "4         1                0                1        2         0   \n",
       "\n",
       "  furnishingstatus  \n",
       "0        furnished  \n",
       "1        furnished  \n",
       "2   semi-furnished  \n",
       "3        furnished  \n",
       "4        furnished  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varlist = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "def binary_map(x):\n",
    "    return x.map({'yes' : 1, \"no\" : 0})\n",
    "housing[varlist] = housing[varlist].apply(binary_map)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77da6496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
       "0         0                0                1        2         1   \n",
       "1         0                0                1        3         0   \n",
       "2         1                0                0        2         1   \n",
       "3         1                0                1        3         1   \n",
       "4         1                0                1        2         0   \n",
       "\n",
       "   furnishingstatus  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varlist = ['furnishingstatus']\n",
    "def binary_map(x):\n",
    "    return x.map({'furnished' : 1, \"unfurnished\" : 0,'semi-furnished': 2})\n",
    "housing[varlist] = housing[varlist].apply(binary_map)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3519b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = housing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ce3390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13300000,     7420,        4, ...,        2,        1,        1],\n",
       "       [12250000,     8960,        4, ...,        3,        0,        1],\n",
       "       [12250000,     9960,        3, ...,        2,        1,        2],\n",
       "       ...,\n",
       "       [ 1750000,     3620,        2, ...,        0,        0,        0],\n",
       "       [ 1750000,     2910,        3, ...,        0,        0,        1],\n",
       "       [ 1750000,     3850,        3, ...,        0,        0,        0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44060205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7951aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b1e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb4fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efccfa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.39656357, 0.6       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.90909091, 0.5024055 , 0.6       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.90909091, 0.57113402, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.13539519, 0.2       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.08659794, 0.4       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.15120275, 0.4       , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e88b149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20de1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe57e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23753bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 10) (82, 10) (82, 10) (381,) (82,) (82,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6a34ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6d8b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\matthew\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\matthew\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21197c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e783db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2dd023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "006e9e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 1s 22ms/step - loss: 0.6747 - accuracy: 0.2835 - val_loss: 0.6824 - val_accuracy: 0.2439\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.2415 - val_loss: 0.6742 - val_accuracy: 0.2317\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6465 - accuracy: 0.2362 - val_loss: 0.6674 - val_accuracy: 0.2439\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.2310 - val_loss: 0.6617 - val_accuracy: 0.2439\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.2310 - val_loss: 0.6571 - val_accuracy: 0.2439\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.2310 - val_loss: 0.6531 - val_accuracy: 0.2439\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.2310 - val_loss: 0.6498 - val_accuracy: 0.2439\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.2310 - val_loss: 0.6472 - val_accuracy: 0.2439\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5933 - accuracy: 0.2310 - val_loss: 0.6450 - val_accuracy: 0.2439\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.2310 - val_loss: 0.6432 - val_accuracy: 0.2439\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.2310 - val_loss: 0.6417 - val_accuracy: 0.2439\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.2310 - val_loss: 0.6404 - val_accuracy: 0.2439\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.2310 - val_loss: 0.6393 - val_accuracy: 0.2439\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.2310 - val_loss: 0.6384 - val_accuracy: 0.2439\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.2310 - val_loss: 0.6376 - val_accuracy: 0.2439\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.2310 - val_loss: 0.6370 - val_accuracy: 0.2439\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.2310 - val_loss: 0.6364 - val_accuracy: 0.2439\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.2310 - val_loss: 0.6358 - val_accuracy: 0.2439\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.2310 - val_loss: 0.6353 - val_accuracy: 0.2439\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.2310 - val_loss: 0.6347 - val_accuracy: 0.2439\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.2310 - val_loss: 0.6341 - val_accuracy: 0.2439\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.2310 - val_loss: 0.6337 - val_accuracy: 0.2439\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.2310 - val_loss: 0.6331 - val_accuracy: 0.2439\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.2310 - val_loss: 0.6324 - val_accuracy: 0.2439\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.2310 - val_loss: 0.6315 - val_accuracy: 0.2439\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.2310 - val_loss: 0.6308 - val_accuracy: 0.2439\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.2310 - val_loss: 0.6299 - val_accuracy: 0.2439\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5396 - accuracy: 0.2310 - val_loss: 0.6288 - val_accuracy: 0.2439\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.2310 - val_loss: 0.6277 - val_accuracy: 0.2439\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.2310 - val_loss: 0.6267 - val_accuracy: 0.2439\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.2310 - val_loss: 0.6258 - val_accuracy: 0.2439\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.2310 - val_loss: 0.6245 - val_accuracy: 0.2439\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.2310 - val_loss: 0.6234 - val_accuracy: 0.2439\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.2310 - val_loss: 0.6222 - val_accuracy: 0.2439\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5301 - accuracy: 0.2310 - val_loss: 0.6207 - val_accuracy: 0.2439\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.2310 - val_loss: 0.6193 - val_accuracy: 0.2439\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.2310 - val_loss: 0.6179 - val_accuracy: 0.2439\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.2310 - val_loss: 0.6166 - val_accuracy: 0.2439\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.2310 - val_loss: 0.6151 - val_accuracy: 0.2439\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.2310 - val_loss: 0.6134 - val_accuracy: 0.2439\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.2310 - val_loss: 0.6119 - val_accuracy: 0.2439\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.2310 - val_loss: 0.6104 - val_accuracy: 0.2439\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.2310 - val_loss: 0.6086 - val_accuracy: 0.2439\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.2310 - val_loss: 0.6066 - val_accuracy: 0.2439\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.2310 - val_loss: 0.6046 - val_accuracy: 0.2439\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.2310 - val_loss: 0.6028 - val_accuracy: 0.2439\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.2310 - val_loss: 0.6008 - val_accuracy: 0.2439\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.2310 - val_loss: 0.5990 - val_accuracy: 0.2439\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.5105 - accuracy: 0.2310 - val_loss: 0.5966 - val_accuracy: 0.2439\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.2310 - val_loss: 0.5944 - val_accuracy: 0.2439\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.2310 - val_loss: 0.5921 - val_accuracy: 0.2439\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.2310 - val_loss: 0.5900 - val_accuracy: 0.2439\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.2310 - val_loss: 0.5877 - val_accuracy: 0.2439\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.2310 - val_loss: 0.5855 - val_accuracy: 0.2439\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.2310 - val_loss: 0.5831 - val_accuracy: 0.2439\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.2310 - val_loss: 0.5807 - val_accuracy: 0.2439\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.2310 - val_loss: 0.5784 - val_accuracy: 0.2439\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.2310 - val_loss: 0.5759 - val_accuracy: 0.2439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.2310 - val_loss: 0.5735 - val_accuracy: 0.2439\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.2310 - val_loss: 0.5710 - val_accuracy: 0.2439\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.2310 - val_loss: 0.5681 - val_accuracy: 0.2439\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4894 - accuracy: 0.2310 - val_loss: 0.5655 - val_accuracy: 0.2439\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4873 - accuracy: 0.2310 - val_loss: 0.5630 - val_accuracy: 0.2439\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.2310 - val_loss: 0.5595 - val_accuracy: 0.2439\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.2310 - val_loss: 0.5565 - val_accuracy: 0.2439\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.2310 - val_loss: 0.5536 - val_accuracy: 0.2439\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.2310 - val_loss: 0.5509 - val_accuracy: 0.2439\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.2310 - val_loss: 0.5477 - val_accuracy: 0.2439\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.2310 - val_loss: 0.5444 - val_accuracy: 0.2439\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.2310 - val_loss: 0.5416 - val_accuracy: 0.2439\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.2310 - val_loss: 0.5380 - val_accuracy: 0.2439\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.2310 - val_loss: 0.5354 - val_accuracy: 0.2439\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.2310 - val_loss: 0.5327 - val_accuracy: 0.2317\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.2310 - val_loss: 0.5300 - val_accuracy: 0.2317\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.2310 - val_loss: 0.5268 - val_accuracy: 0.2317\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.2310 - val_loss: 0.5232 - val_accuracy: 0.2317\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.2336 - val_loss: 0.5201 - val_accuracy: 0.2317\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.2336 - val_loss: 0.5167 - val_accuracy: 0.2439\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.2336 - val_loss: 0.5133 - val_accuracy: 0.2439\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.2336 - val_loss: 0.5101 - val_accuracy: 0.2439\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.2336 - val_loss: 0.5063 - val_accuracy: 0.2439\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4470 - accuracy: 0.2336 - val_loss: 0.5029 - val_accuracy: 0.2439\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.2336 - val_loss: 0.4986 - val_accuracy: 0.2439\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.2310 - val_loss: 0.4949 - val_accuracy: 0.2439\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.2336 - val_loss: 0.4910 - val_accuracy: 0.2439\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.2336 - val_loss: 0.4870 - val_accuracy: 0.2439\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.2388 - val_loss: 0.4839 - val_accuracy: 0.2561\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.2388 - val_loss: 0.4799 - val_accuracy: 0.2561\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.2388 - val_loss: 0.4766 - val_accuracy: 0.2561\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.2415 - val_loss: 0.4724 - val_accuracy: 0.2561\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.2441 - val_loss: 0.4686 - val_accuracy: 0.2561\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.2441 - val_loss: 0.4653 - val_accuracy: 0.2561\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.2441 - val_loss: 0.4612 - val_accuracy: 0.2683\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.2441 - val_loss: 0.4568 - val_accuracy: 0.2683\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.2493 - val_loss: 0.4523 - val_accuracy: 0.2683\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.2493 - val_loss: 0.4481 - val_accuracy: 0.2683\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.2493 - val_loss: 0.4438 - val_accuracy: 0.2683\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.2520 - val_loss: 0.4392 - val_accuracy: 0.2805\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.2546 - val_loss: 0.4351 - val_accuracy: 0.2805\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.2572 - val_loss: 0.4305 - val_accuracy: 0.2805\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.2625 - val_loss: 0.4257 - val_accuracy: 0.2805\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.2677 - val_loss: 0.4219 - val_accuracy: 0.2805\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.2677 - val_loss: 0.4179 - val_accuracy: 0.2805\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.2677 - val_loss: 0.4133 - val_accuracy: 0.2683\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.2651 - val_loss: 0.4096 - val_accuracy: 0.2805\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.2651 - val_loss: 0.4046 - val_accuracy: 0.2927\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.2651 - val_loss: 0.3998 - val_accuracy: 0.3049\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.2651 - val_loss: 0.3944 - val_accuracy: 0.3171\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3705 - accuracy: 0.2703 - val_loss: 0.3894 - val_accuracy: 0.3171\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3671 - accuracy: 0.2730 - val_loss: 0.3839 - val_accuracy: 0.3293\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.2730 - val_loss: 0.3786 - val_accuracy: 0.3171\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.2756 - val_loss: 0.3732 - val_accuracy: 0.3293\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.2808 - val_loss: 0.3684 - val_accuracy: 0.3293\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3528 - accuracy: 0.2782 - val_loss: 0.3628 - val_accuracy: 0.3293\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.2808 - val_loss: 0.3574 - val_accuracy: 0.3293\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.2861 - val_loss: 0.3525 - val_accuracy: 0.3293\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.2835 - val_loss: 0.3467 - val_accuracy: 0.3293\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.2887 - val_loss: 0.3421 - val_accuracy: 0.3293\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.2835 - val_loss: 0.3349 - val_accuracy: 0.3293\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.2966 - val_loss: 0.3301 - val_accuracy: 0.3293\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.2966 - val_loss: 0.3249 - val_accuracy: 0.3293\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.2940 - val_loss: 0.3201 - val_accuracy: 0.3293\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.2940 - val_loss: 0.3139 - val_accuracy: 0.3293\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.2913 - val_loss: 0.3062 - val_accuracy: 0.3293\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.3045 - val_loss: 0.3019 - val_accuracy: 0.3293\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3066 - accuracy: 0.2992 - val_loss: 0.2966 - val_accuracy: 0.3293\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3015 - accuracy: 0.2940 - val_loss: 0.2883 - val_accuracy: 0.3171\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.2940 - val_loss: 0.2801 - val_accuracy: 0.3171\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.3097 - val_loss: 0.2745 - val_accuracy: 0.3171\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.3150 - val_loss: 0.2703 - val_accuracy: 0.3171\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.3071 - val_loss: 0.2633 - val_accuracy: 0.3171\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.3176 - val_loss: 0.2579 - val_accuracy: 0.3171\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.3018 - val_loss: 0.2497 - val_accuracy: 0.3171\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.3150 - val_loss: 0.2435 - val_accuracy: 0.3171\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.3097 - val_loss: 0.2347 - val_accuracy: 0.3171\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.3333 - val_loss: 0.2319 - val_accuracy: 0.3171\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.3123 - val_loss: 0.2223 - val_accuracy: 0.3171\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.3281 - val_loss: 0.2160 - val_accuracy: 0.3171\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2441 - accuracy: 0.3202 - val_loss: 0.2070 - val_accuracy: 0.3293\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.3228 - val_loss: 0.2004 - val_accuracy: 0.3293\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.3255 - val_loss: 0.1911 - val_accuracy: 0.3293\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.3360 - val_loss: 0.1855 - val_accuracy: 0.3293\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2246 - accuracy: 0.3333 - val_loss: 0.1786 - val_accuracy: 0.3293\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2194 - accuracy: 0.3255 - val_loss: 0.1689 - val_accuracy: 0.3415\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2148 - accuracy: 0.3438 - val_loss: 0.1660 - val_accuracy: 0.3293\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.3228 - val_loss: 0.1507 - val_accuracy: 0.3780\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.3333 - val_loss: 0.1418 - val_accuracy: 0.3902\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.3438 - val_loss: 0.1347 - val_accuracy: 0.3780\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1902 - accuracy: 0.3360 - val_loss: 0.1260 - val_accuracy: 0.3780\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1857 - accuracy: 0.3438 - val_loss: 0.1190 - val_accuracy: 0.3780\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.3333 - val_loss: 0.1080 - val_accuracy: 0.3902\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.3412 - val_loss: 0.1010 - val_accuracy: 0.3780\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.3412 - val_loss: 0.0911 - val_accuracy: 0.3902\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.3412 - val_loss: 0.0796 - val_accuracy: 0.3780\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.3360 - val_loss: 0.0662 - val_accuracy: 0.3780\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.3491 - val_loss: 0.0576 - val_accuracy: 0.3780\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.3517 - val_loss: 0.0483 - val_accuracy: 0.3780\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.3491 - val_loss: 0.0412 - val_accuracy: 0.3780\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.3438 - val_loss: 0.0279 - val_accuracy: 0.3902\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.3491 - val_loss: 0.0168 - val_accuracy: 0.4024\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.3648 - val_loss: 0.0073 - val_accuracy: 0.3902\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.3491 - val_loss: -0.0039 - val_accuracy: 0.4024\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.3596 - val_loss: -0.0122 - val_accuracy: 0.3902\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0909 - accuracy: 0.3596 - val_loss: -0.0226 - val_accuracy: 0.3902\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.3648 - val_loss: -0.0311 - val_accuracy: 0.3902\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.3727 - val_loss: -0.0342 - val_accuracy: 0.4024\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.3517 - val_loss: -0.0534 - val_accuracy: 0.3902\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.3517 - val_loss: -0.0725 - val_accuracy: 0.4024\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.3701 - val_loss: -0.0839 - val_accuracy: 0.4024\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.3675 - val_loss: -0.0966 - val_accuracy: 0.4024\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.3832 - val_loss: -0.1055 - val_accuracy: 0.4024\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.3543 - val_loss: -0.1227 - val_accuracy: 0.4024\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.3937 - val_loss: -0.1267 - val_accuracy: 0.4146\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.3622 - val_loss: -0.1427 - val_accuracy: 0.4024\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.3780 - val_loss: -0.1540 - val_accuracy: 0.4146\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: -0.0037 - accuracy: 0.3727 - val_loss: -0.1714 - val_accuracy: 0.4024\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: -0.0121 - accuracy: 0.3727 - val_loss: -0.1863 - val_accuracy: 0.4024\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: -0.0273 - accuracy: 0.3753 - val_loss: -0.2023 - val_accuracy: 0.4024\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.0308 - accuracy: 0.3727 - val_loss: -0.2211 - val_accuracy: 0.4146\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.0396 - accuracy: 0.3701 - val_loss: -0.2366 - val_accuracy: 0.4146\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -0.0523 - accuracy: 0.3937 - val_loss: -0.2490 - val_accuracy: 0.4024\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.0528 - accuracy: 0.3963 - val_loss: -0.2565 - val_accuracy: 0.4146\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: -0.0676 - accuracy: 0.3727 - val_loss: -0.2765 - val_accuracy: 0.4268\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: -0.0734 - accuracy: 0.4016 - val_loss: -0.2834 - val_accuracy: 0.4146\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.0831 - accuracy: 0.3701 - val_loss: -0.3066 - val_accuracy: 0.4268\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: -0.0968 - accuracy: 0.3648 - val_loss: -0.3311 - val_accuracy: 0.4146\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: -0.1019 - accuracy: 0.3963 - val_loss: -0.3456 - val_accuracy: 0.4268\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: -0.1180 - accuracy: 0.3911 - val_loss: -0.3632 - val_accuracy: 0.4268\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: -0.1387 - accuracy: 0.4042 - val_loss: -0.3682 - val_accuracy: 0.4268\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: -0.1311 - accuracy: 0.3937 - val_loss: -0.3760 - val_accuracy: 0.4146\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: -0.1505 - accuracy: 0.4042 - val_loss: -0.3929 - val_accuracy: 0.4146\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: -0.1510 - accuracy: 0.3780 - val_loss: -0.4320 - val_accuracy: 0.4146\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.1720 - accuracy: 0.3990 - val_loss: -0.4505 - val_accuracy: 0.4146\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.1892 - accuracy: 0.3937 - val_loss: -0.4691 - val_accuracy: 0.4146\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.1884 - accuracy: 0.3911 - val_loss: -0.4940 - val_accuracy: 0.4268\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -0.2233 - accuracy: 0.3911 - val_loss: -0.5196 - val_accuracy: 0.4268\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -0.2315 - accuracy: 0.4121 - val_loss: -0.5373 - val_accuracy: 0.4268\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -0.2291 - accuracy: 0.3780 - val_loss: -0.5597 - val_accuracy: 0.4268\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.2436 - accuracy: 0.4199 - val_loss: -0.5821 - val_accuracy: 0.4268\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -0.2594 - accuracy: 0.4016 - val_loss: -0.5970 - val_accuracy: 0.4146\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=200,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "630c7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.3659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3658536672592163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e850f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b2739af10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4c46f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.5759 - accuracy: 0.2441 - val_loss: 0.4906 - val_accuracy: 0.2317\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.4745 - accuracy: 0.2756 - val_loss: 0.3596 - val_accuracy: 0.5488\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2349 - accuracy: 0.4304 - val_loss: -0.3877 - val_accuracy: 0.3171\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -0.4076 - accuracy: 0.4068 - val_loss: -2.8000 - val_accuracy: 0.4146\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 1s 42ms/step - loss: -2.8416 - accuracy: 0.4357 - val_loss: -12.3021 - val_accuracy: 0.6098\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -18.0750 - accuracy: 0.3832 - val_loss: -73.2736 - val_accuracy: 0.5244\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -38.3253 - accuracy: 0.4199 - val_loss: -127.9526 - val_accuracy: 0.6220\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -137.2475 - accuracy: 0.4803 - val_loss: -373.5557 - val_accuracy: 0.2439\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -352.2806 - accuracy: 0.2310 - val_loss: -828.7402 - val_accuracy: 0.2439\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -1086.4706 - accuracy: 0.3858 - val_loss: -2891.7288 - val_accuracy: 0.5732\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: -3276.7959 - accuracy: 0.4961 - val_loss: -8297.6025 - val_accuracy: 0.4756\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -6965.7979 - accuracy: 0.4462 - val_loss: -16883.9785 - val_accuracy: 0.6341\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -16171.6641 - accuracy: 0.3255 - val_loss: -38177.9375 - val_accuracy: 0.5488\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -27772.0391 - accuracy: 0.4304 - val_loss: -68598.1953 - val_accuracy: 0.5854\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -39177.3047 - accuracy: 0.3570 - val_loss: -88515.6953 - val_accuracy: 0.2439\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -73696.7422 - accuracy: 0.4383 - val_loss: -159731.2188 - val_accuracy: 0.5488\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -95709.0156 - accuracy: 0.4094 - val_loss: -261425.1250 - val_accuracy: 0.5610\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -136447.4688 - accuracy: 0.4147 - val_loss: -272760.9688 - val_accuracy: 0.2439\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -232187.7812 - accuracy: 0.3806 - val_loss: -460062.8750 - val_accuracy: 0.5488\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: -323040.2188 - accuracy: 0.4357 - val_loss: -687384.0000 - val_accuracy: 0.2439\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: -491259.1250 - accuracy: 0.3990 - val_loss: -1005853.0625 - val_accuracy: 0.2317\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -740584.7500 - accuracy: 0.3543 - val_loss: -1410774.5000 - val_accuracy: 0.5488\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -956047.9375 - accuracy: 0.4514 - val_loss: -1917106.1250 - val_accuracy: 0.5610\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -1262349.5000 - accuracy: 0.3963 - val_loss: -2677315.0000 - val_accuracy: 0.5610\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -1773042.2500 - accuracy: 0.4252 - val_loss: -3409458.7500 - val_accuracy: 0.5488\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -2339696.0000 - accuracy: 0.3832 - val_loss: -4521373.0000 - val_accuracy: 0.5610\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -3106322.7500 - accuracy: 0.4252 - val_loss: -5774426.5000 - val_accuracy: 0.5488\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -3945750.5000 - accuracy: 0.4672 - val_loss: -7414436.0000 - val_accuracy: 0.2317\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -4970197.5000 - accuracy: 0.3832 - val_loss: -9609165.0000 - val_accuracy: 0.5366\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -6332888.5000 - accuracy: 0.4646 - val_loss: -11868102.0000 - val_accuracy: 0.5244\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -7612324.0000 - accuracy: 0.4672 - val_loss: -14064982.0000 - val_accuracy: 0.2439\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -9226081.0000 - accuracy: 0.3517 - val_loss: -18231148.0000 - val_accuracy: 0.2439\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -11062571.0000 - accuracy: 0.4226 - val_loss: -21128724.0000 - val_accuracy: 0.2439\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -12120846.0000 - accuracy: 0.4068 - val_loss: -26190518.0000 - val_accuracy: 0.5488\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 31ms/step - loss: -15708501.0000 - accuracy: 0.4226 - val_loss: -28096272.0000 - val_accuracy: 0.5854\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -19571942.0000 - accuracy: 0.4908 - val_loss: -36174488.0000 - val_accuracy: 0.5488\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -23105694.0000 - accuracy: 0.4698 - val_loss: -42861044.0000 - val_accuracy: 0.2439\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -27306038.0000 - accuracy: 0.2940 - val_loss: -50552240.0000 - val_accuracy: 0.5366\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: -32402164.0000 - accuracy: 0.4882 - val_loss: -57271572.0000 - val_accuracy: 0.5732\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -37491788.0000 - accuracy: 0.3255 - val_loss: -68927136.0000 - val_accuracy: 0.2439\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -42669404.0000 - accuracy: 0.2310 - val_loss: -77991624.0000 - val_accuracy: 0.2439\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -51677668.0000 - accuracy: 0.2310 - val_loss: -90561864.0000 - val_accuracy: 0.2439\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -58870708.0000 - accuracy: 0.2310 - val_loss: -107060360.0000 - val_accuracy: 0.2439\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -66623956.0000 - accuracy: 0.4619 - val_loss: -121953008.0000 - val_accuracy: 0.5976\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 31ms/step - loss: -78405888.0000 - accuracy: 0.4777 - val_loss: -142649536.0000 - val_accuracy: 0.5488\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -89804776.0000 - accuracy: 0.4672 - val_loss: -163373632.0000 - val_accuracy: 0.5732\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -100613264.0000 - accuracy: 0.4567 - val_loss: -188580368.0000 - val_accuracy: 0.5732\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -109901832.0000 - accuracy: 0.5066 - val_loss: -202147184.0000 - val_accuracy: 0.5976\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 1s 43ms/step - loss: -124104040.0000 - accuracy: 0.4803 - val_loss: -232362832.0000 - val_accuracy: 0.5366\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -141406064.0000 - accuracy: 0.4567 - val_loss: -252665360.0000 - val_accuracy: 0.5732\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -158632656.0000 - accuracy: 0.4698 - val_loss: -289022336.0000 - val_accuracy: 0.5488\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 28ms/step - loss: -179049056.0000 - accuracy: 0.4646 - val_loss: -317063456.0000 - val_accuracy: 0.5732\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -195221168.0000 - accuracy: 0.4803 - val_loss: -360956064.0000 - val_accuracy: 0.5732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -216679456.0000 - accuracy: 0.4934 - val_loss: -384614656.0000 - val_accuracy: 0.5854\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -240222560.0000 - accuracy: 0.4672 - val_loss: -435618848.0000 - val_accuracy: 0.5488\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 30ms/step - loss: -268569760.0000 - accuracy: 0.4619 - val_loss: -477172800.0000 - val_accuracy: 0.5732\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -292452896.0000 - accuracy: 0.5039 - val_loss: -516530624.0000 - val_accuracy: 0.5854\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -320760672.0000 - accuracy: 0.4672 - val_loss: -579709056.0000 - val_accuracy: 0.5366\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -348403392.0000 - accuracy: 0.4567 - val_loss: -650419456.0000 - val_accuracy: 0.5610\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -393456672.0000 - accuracy: 0.4829 - val_loss: -682169792.0000 - val_accuracy: 0.5976\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -419162880.0000 - accuracy: 0.4856 - val_loss: -756893376.0000 - val_accuracy: 0.5732\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -460173056.0000 - accuracy: 0.4777 - val_loss: -812597120.0000 - val_accuracy: 0.5854\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 31ms/step - loss: -506986272.0000 - accuracy: 0.4829 - val_loss: -884631488.0000 - val_accuracy: 0.5610\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -544500032.0000 - accuracy: 0.4882 - val_loss: -950086208.0000 - val_accuracy: 0.5854\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -567595840.0000 - accuracy: 0.4436 - val_loss: -1048833856.0000 - val_accuracy: 0.5488\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -642204032.0000 - accuracy: 0.4934 - val_loss: -1097093376.0000 - val_accuracy: 0.5854\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -680484928.0000 - accuracy: 0.4777 - val_loss: -1205838336.0000 - val_accuracy: 0.5732\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -748513472.0000 - accuracy: 0.4751 - val_loss: -1293212672.0000 - val_accuracy: 0.5732\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -797045312.0000 - accuracy: 0.4934 - val_loss: -1384139904.0000 - val_accuracy: 0.5732\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -865760832.0000 - accuracy: 0.4829 - val_loss: -1518097920.0000 - val_accuracy: 0.5488\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -931460480.0000 - accuracy: 0.4567 - val_loss: -1634950912.0000 - val_accuracy: 0.5610\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -1014599552.0000 - accuracy: 0.4856 - val_loss: -1772469248.0000 - val_accuracy: 0.5610\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -1082959744.0000 - accuracy: 0.4908 - val_loss: -1857234048.0000 - val_accuracy: 0.5976\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -1072443776.0000 - accuracy: 0.4541 - val_loss: -2039919872.0000 - val_accuracy: 0.5488\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -1231130112.0000 - accuracy: 0.4672 - val_loss: -2182592512.0000 - val_accuracy: 0.5854\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -1314989824.0000 - accuracy: 0.4987 - val_loss: -2279914752.0000 - val_accuracy: 0.5976\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -1427668096.0000 - accuracy: 0.4856 - val_loss: -2457713920.0000 - val_accuracy: 0.5610\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -1517355136.0000 - accuracy: 0.4751 - val_loss: -2612702976.0000 - val_accuracy: 0.5610\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -1569340160.0000 - accuracy: 0.4593 - val_loss: -2837939200.0000 - val_accuracy: 0.5488\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -1731103104.0000 - accuracy: 0.4882 - val_loss: -2969922560.0000 - val_accuracy: 0.5976\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -1822928768.0000 - accuracy: 0.4987 - val_loss: -3122549248.0000 - val_accuracy: 0.5854\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 30ms/step - loss: -1894989568.0000 - accuracy: 0.4672 - val_loss: -3393907712.0000 - val_accuracy: 0.5488\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -2069171712.0000 - accuracy: 0.4698 - val_loss: -3597494016.0000 - val_accuracy: 0.5732\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -2207864064.0000 - accuracy: 0.4829 - val_loss: -3789958912.0000 - val_accuracy: 0.5854\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -2323152896.0000 - accuracy: 0.4856 - val_loss: -3984954112.0000 - val_accuracy: 0.5854\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -2482221824.0000 - accuracy: 0.4856 - val_loss: -4240475648.0000 - val_accuracy: 0.5732\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 1s 42ms/step - loss: -2611115008.0000 - accuracy: 0.4724 - val_loss: -4504217088.0000 - val_accuracy: 0.5610\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -2790531840.0000 - accuracy: 0.4856 - val_loss: -4766802432.0000 - val_accuracy: 0.5732\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -2950336512.0000 - accuracy: 0.4724 - val_loss: -5083468800.0000 - val_accuracy: 0.5610\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -3105182720.0000 - accuracy: 0.4829 - val_loss: -5308442624.0000 - val_accuracy: 0.5854\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -3262475264.0000 - accuracy: 0.4672 - val_loss: -5726839296.0000 - val_accuracy: 0.5488\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -3507264512.0000 - accuracy: 0.4803 - val_loss: -6049967616.0000 - val_accuracy: 0.5732\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 30ms/step - loss: -3662088960.0000 - accuracy: 0.4908 - val_loss: -6250312192.0000 - val_accuracy: 0.5732\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -3908532992.0000 - accuracy: 0.4803 - val_loss: -6731586048.0000 - val_accuracy: 0.5488\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -4130941440.0000 - accuracy: 0.4672 - val_loss: -7094989824.0000 - val_accuracy: 0.5732\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -4296545792.0000 - accuracy: 0.4961 - val_loss: -7398990336.0000 - val_accuracy: 0.5854\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -4568641024.0000 - accuracy: 0.4698 - val_loss: -7905617408.0000 - val_accuracy: 0.5610\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -4811694592.0000 - accuracy: 0.4829 - val_loss: -8251246080.0000 - val_accuracy: 0.5732\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 31ms/step - loss: -5097455616.0000 - accuracy: 0.4803 - val_loss: -8625286144.0000 - val_accuracy: 0.5854\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 31ms/step - loss: -5301719040.0000 - accuracy: 0.4646 - val_loss: -9117162496.0000 - val_accuracy: 0.5610\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -5605879296.0000 - accuracy: 0.4751 - val_loss: -9584318464.0000 - val_accuracy: 0.5854\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -5880110080.0000 - accuracy: 0.4908 - val_loss: -9996281856.0000 - val_accuracy: 0.5854\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: -6165867008.0000 - accuracy: 0.4698 - val_loss: -10650431488.0000 - val_accuracy: 0.5610\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 38ms/step - loss: -6267801600.0000 - accuracy: 0.4593 - val_loss: -11218871296.0000 - val_accuracy: 0.5610\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -6816623104.0000 - accuracy: 0.4829 - val_loss: -11648899072.0000 - val_accuracy: 0.5854\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -7102361600.0000 - accuracy: 0.4829 - val_loss: -12109901824.0000 - val_accuracy: 0.5854\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -7438119424.0000 - accuracy: 0.4829 - val_loss: -12745867264.0000 - val_accuracy: 0.5732\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -7844551168.0000 - accuracy: 0.4777 - val_loss: -13233286144.0000 - val_accuracy: 0.5732\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -8136991744.0000 - accuracy: 0.4829 - val_loss: -13998441472.0000 - val_accuracy: 0.5732\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -8579823616.0000 - accuracy: 0.4829 - val_loss: -14615221248.0000 - val_accuracy: 0.5732\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -8907230208.0000 - accuracy: 0.4829 - val_loss: -15330379776.0000 - val_accuracy: 0.5732\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -9280431104.0000 - accuracy: 0.4751 - val_loss: -16063266816.0000 - val_accuracy: 0.5732\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -9741698048.0000 - accuracy: 0.4882 - val_loss: -16485994496.0000 - val_accuracy: 0.5854\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -10150432768.0000 - accuracy: 0.4856 - val_loss: -17350848512.0000 - val_accuracy: 0.5610\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -10625265664.0000 - accuracy: 0.4803 - val_loss: -17956698112.0000 - val_accuracy: 0.5732\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 29ms/step - loss: -10966835200.0000 - accuracy: 0.4751 - val_loss: -18886522880.0000 - val_accuracy: 0.5732\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -11530857472.0000 - accuracy: 0.4829 - val_loss: -19719884800.0000 - val_accuracy: 0.5854\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -12118647808.0000 - accuracy: 0.4803 - val_loss: -20562944000.0000 - val_accuracy: 0.5732\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -12475868160.0000 - accuracy: 0.4724 - val_loss: -21346627584.0000 - val_accuracy: 0.5732\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -13016242176.0000 - accuracy: 0.4777 - val_loss: -22357422080.0000 - val_accuracy: 0.5610\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 32ms/step - loss: -13599367168.0000 - accuracy: 0.4882 - val_loss: -23107502080.0000 - val_accuracy: 0.5732\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -14169872384.0000 - accuracy: 0.4829 - val_loss: -24120911872.0000 - val_accuracy: 0.5732\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -14691141632.0000 - accuracy: 0.4672 - val_loss: -25291560960.0000 - val_accuracy: 0.5732\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -15412128768.0000 - accuracy: 0.4803 - val_loss: -25831522304.0000 - val_accuracy: 0.5854\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -15729489920.0000 - accuracy: 0.4856 - val_loss: -27243599872.0000 - val_accuracy: 0.5610\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -16507320320.0000 - accuracy: 0.4751 - val_loss: -28212021248.0000 - val_accuracy: 0.5732\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -17095847936.0000 - accuracy: 0.4856 - val_loss: -29244540928.0000 - val_accuracy: 0.5854\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -17644730368.0000 - accuracy: 0.4908 - val_loss: -30510551040.0000 - val_accuracy: 0.5610\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -18493046784.0000 - accuracy: 0.4777 - val_loss: -31446304768.0000 - val_accuracy: 0.5732\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -18935207936.0000 - accuracy: 0.4724 - val_loss: -32910237696.0000 - val_accuracy: 0.5610\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -19777280000.0000 - accuracy: 0.4856 - val_loss: -33571547136.0000 - val_accuracy: 0.5854\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -20464496640.0000 - accuracy: 0.4829 - val_loss: -35158822912.0000 - val_accuracy: 0.5732\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -21167200256.0000 - accuracy: 0.4803 - val_loss: -36418781184.0000 - val_accuracy: 0.5610\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: -22091933696.0000 - accuracy: 0.4803 - val_loss: -37605085184.0000 - val_accuracy: 0.5732\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -22838923264.0000 - accuracy: 0.4882 - val_loss: -38814134272.0000 - val_accuracy: 0.5732\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -23640512512.0000 - accuracy: 0.4882 - val_loss: -40085884928.0000 - val_accuracy: 0.5732\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -24383242240.0000 - accuracy: 0.4908 - val_loss: -41215553536.0000 - val_accuracy: 0.5732\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -25242331136.0000 - accuracy: 0.4724 - val_loss: -42828238848.0000 - val_accuracy: 0.5610\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: -25994977280.0000 - accuracy: 0.4777 - val_loss: -44346748928.0000 - val_accuracy: 0.5732\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -27070877696.0000 - accuracy: 0.4829 - val_loss: -45743915008.0000 - val_accuracy: 0.5732\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -27628197888.0000 - accuracy: 0.4829 - val_loss: -46786801664.0000 - val_accuracy: 0.5854\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: -28710275072.0000 - accuracy: 0.4882 - val_loss: -48936931328.0000 - val_accuracy: 0.5610\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -29643513856.0000 - accuracy: 0.4672 - val_loss: -50717941760.0000 - val_accuracy: 0.5610\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -30805448704.0000 - accuracy: 0.4829 - val_loss: -52156174336.0000 - val_accuracy: 0.5732\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -31689277440.0000 - accuracy: 0.4882 - val_loss: -53711732736.0000 - val_accuracy: 0.5854\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 1s 47ms/step - loss: -32512081920.0000 - accuracy: 0.4777 - val_loss: -55569801216.0000 - val_accuracy: 0.5610\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -33771409408.0000 - accuracy: 0.4803 - val_loss: -57341878272.0000 - val_accuracy: 0.5854\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -34660892672.0000 - accuracy: 0.4803 - val_loss: -59392532480.0000 - val_accuracy: 0.5732\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -35456585728.0000 - accuracy: 0.4803 - val_loss: -61519859712.0000 - val_accuracy: 0.5610\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -37195227136.0000 - accuracy: 0.4856 - val_loss: -62764867584.0000 - val_accuracy: 0.5854\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: -37929816064.0000 - accuracy: 0.4934 - val_loss: -64328986624.0000 - val_accuracy: 0.5854\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -39349866496.0000 - accuracy: 0.4724 - val_loss: -66665181184.0000 - val_accuracy: 0.5610\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 38ms/step - loss: -40392998912.0000 - accuracy: 0.4751 - val_loss: -68496379904.0000 - val_accuracy: 0.5732\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -41467904000.0000 - accuracy: 0.4882 - val_loss: -70540722176.0000 - val_accuracy: 0.5732\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -42750881792.0000 - accuracy: 0.4856 - val_loss: -73120260096.0000 - val_accuracy: 0.5732\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -44165398528.0000 - accuracy: 0.4777 - val_loss: -74953138176.0000 - val_accuracy: 0.5732\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -45401624576.0000 - accuracy: 0.4829 - val_loss: -77038944256.0000 - val_accuracy: 0.5732\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -46829608960.0000 - accuracy: 0.4856 - val_loss: -79266799616.0000 - val_accuracy: 0.5732\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: -47949160448.0000 - accuracy: 0.4777 - val_loss: -81193787392.0000 - val_accuracy: 0.5732\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 35ms/step - loss: -48865574912.0000 - accuracy: 0.4803 - val_loss: -84274561024.0000 - val_accuracy: 0.5732\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: -50780102656.0000 - accuracy: 0.4829 - val_loss: -86186311680.0000 - val_accuracy: 0.5732\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -52391809024.0000 - accuracy: 0.4856 - val_loss: -88724922368.0000 - val_accuracy: 0.5732\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -53478965248.0000 - accuracy: 0.4882 - val_loss: -90456383488.0000 - val_accuracy: 0.5854\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 1s 43ms/step - loss: -54974496768.0000 - accuracy: 0.4751 - val_loss: -93756817408.0000 - val_accuracy: 0.5610\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: -56702636032.0000 - accuracy: 0.4724 - val_loss: -95940648960.0000 - val_accuracy: 0.5732\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: -58341380096.0000 - accuracy: 0.4829 - val_loss: -98928074752.0000 - val_accuracy: 0.5732\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -59843866624.0000 - accuracy: 0.4777 - val_loss: -101877587968.0000 - val_accuracy: 0.5732\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -61570543616.0000 - accuracy: 0.4777 - val_loss: -104713805824.0000 - val_accuracy: 0.5732\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: -63097442304.0000 - accuracy: 0.4856 - val_loss: -106646265856.0000 - val_accuracy: 0.5854\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 1s 47ms/step - loss: -64883556352.0000 - accuracy: 0.4856 - val_loss: -110477049856.0000 - val_accuracy: 0.5732\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 1s 42ms/step - loss: -66971496448.0000 - accuracy: 0.4672 - val_loss: -113450721280.0000 - val_accuracy: 0.5732\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -68482392064.0000 - accuracy: 0.4882 - val_loss: -116433453056.0000 - val_accuracy: 0.5732\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -70633390080.0000 - accuracy: 0.4856 - val_loss: -119506337792.0000 - val_accuracy: 0.5732\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -72496521216.0000 - accuracy: 0.4829 - val_loss: -122437132288.0000 - val_accuracy: 0.5732\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: -74394394624.0000 - accuracy: 0.4803 - val_loss: -126269652992.0000 - val_accuracy: 0.5732\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: -76196282368.0000 - accuracy: 0.4829 - val_loss: -128791601152.0000 - val_accuracy: 0.5854\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: -78305533952.0000 - accuracy: 0.4829 - val_loss: -132783890432.0000 - val_accuracy: 0.5732\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 1s 69ms/step - loss: -80075980800.0000 - accuracy: 0.4751 - val_loss: -137045508096.0000 - val_accuracy: 0.5610\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -82526314496.0000 - accuracy: 0.4856 - val_loss: -139445092352.0000 - val_accuracy: 0.5854\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -83674628096.0000 - accuracy: 0.4961 - val_loss: -143255846912.0000 - val_accuracy: 0.5732\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 1s 42ms/step - loss: -86817325056.0000 - accuracy: 0.4698 - val_loss: -146570838016.0000 - val_accuracy: 0.5732\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -89100025856.0000 - accuracy: 0.4829 - val_loss: -150854057984.0000 - val_accuracy: 0.5732\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 1s 75ms/step - loss: -90840547328.0000 - accuracy: 0.4777 - val_loss: -154554892288.0000 - val_accuracy: 0.5854\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -93592936448.0000 - accuracy: 0.4882 - val_loss: -158360371200.0000 - val_accuracy: 0.5732\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -94825152512.0000 - accuracy: 0.4672 - val_loss: -163600203776.0000 - val_accuracy: 0.5488\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 34ms/step - loss: -98058657792.0000 - accuracy: 0.4803 - val_loss: -165618532352.0000 - val_accuracy: 0.5732\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: -99729981440.0000 - accuracy: 0.4882 - val_loss: -171241242624.0000 - val_accuracy: 0.5732\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -102995263488.0000 - accuracy: 0.4882 - val_loss: -174466646016.0000 - val_accuracy: 0.5732\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -104935530496.0000 - accuracy: 0.4803 - val_loss: -179318947840.0000 - val_accuracy: 0.5488\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: -108387155968.0000 - accuracy: 0.4803 - val_loss: -182206185472.0000 - val_accuracy: 0.5732\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: -109940613120.0000 - accuracy: 0.4856 - val_loss: -186997440512.0000 - val_accuracy: 0.5732\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -112430997504.0000 - accuracy: 0.4882 - val_loss: -190830985216.0000 - val_accuracy: 0.5732\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -116058857472.0000 - accuracy: 0.4856 - val_loss: -195343859712.0000 - val_accuracy: 0.5732\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -118529777664.0000 - accuracy: 0.4751 - val_loss: -200075493376.0000 - val_accuracy: 0.5732\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: -120696537088.0000 - accuracy: 0.4672 - val_loss: -205832978432.0000 - val_accuracy: 0.5610\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: -123240243200.0000 - accuracy: 0.4856 - val_loss: -208556834816.0000 - val_accuracy: 0.5854\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: -126543167488.0000 - accuracy: 0.4856 - val_loss: -214463610880.0000 - val_accuracy: 0.5732\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -128764952576.0000 - accuracy: 0.4751 - val_loss: -220563947520.0000 - val_accuracy: 0.5488\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: -131872980992.0000 - accuracy: 0.4803 - val_loss: -223693668352.0000 - val_accuracy: 0.5732\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: -135333625856.0000 - accuracy: 0.4856 - val_loss: -228745527296.0000 - val_accuracy: 0.5732\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(1000, activation='relu', input_shape=(10,)),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "hist_2 = model_2.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=200,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbab650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 44522594304.0000 - accuracy: 0.4390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4390243887901306"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9adc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ba77e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2layer = Sequential([\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(10,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25e4222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 2s 73ms/step - loss: 23.5134 - accuracy: 0.2362 - val_loss: 16.0831 - val_accuracy: 0.2439\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 11.7951 - accuracy: 0.2310 - val_loss: 7.6676 - val_accuracy: 0.2439\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 5.5453 - accuracy: 0.2310 - val_loss: 3.5255 - val_accuracy: 0.2439\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 2.5505 - accuracy: 0.2310 - val_loss: 1.6600 - val_accuracy: 0.2561\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.3048 - accuracy: 0.2546 - val_loss: 0.7402 - val_accuracy: 0.3659\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.8390 - accuracy: 0.2992 - val_loss: 0.3590 - val_accuracy: 0.5610\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.4114 - accuracy: 0.4409 - val_loss: -0.9587 - val_accuracy: 0.3902\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -0.3113 - accuracy: 0.3622 - val_loss: -3.9208 - val_accuracy: 0.6098\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -2.6866 - accuracy: 0.4908 - val_loss: -16.2263 - val_accuracy: 0.3415\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -17.6535 - accuracy: 0.4147 - val_loss: -79.5019 - val_accuracy: 0.5244\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: -73.8812 - accuracy: 0.4331 - val_loss: -318.2317 - val_accuracy: 0.5854\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -274.9705 - accuracy: 0.5118 - val_loss: -942.4977 - val_accuracy: 0.5366\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 1s 67ms/step - loss: -866.0508 - accuracy: 0.4777 - val_loss: -2258.1870 - val_accuracy: 0.5610\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -2342.8521 - accuracy: 0.4593 - val_loss: -5240.7690 - val_accuracy: 0.5488\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: -5630.2207 - accuracy: 0.4514 - val_loss: -12419.8945 - val_accuracy: 0.5488\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -11218.7822 - accuracy: 0.2756 - val_loss: -24677.6953 - val_accuracy: 0.2439\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -23464.7539 - accuracy: 0.3307 - val_loss: -42755.5977 - val_accuracy: 0.5366\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -40262.1172 - accuracy: 0.3412 - val_loss: -66190.5391 - val_accuracy: 0.2439\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -59891.8203 - accuracy: 0.3150 - val_loss: -115412.4766 - val_accuracy: 0.5488\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 1s 60ms/step - loss: -92110.7500 - accuracy: 0.3202 - val_loss: -186671.4219 - val_accuracy: 0.2439\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -151935.7500 - accuracy: 0.3255 - val_loss: -284976.9688 - val_accuracy: 0.5244\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -255483.0000 - accuracy: 0.3333 - val_loss: -429505.4062 - val_accuracy: 0.5366\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -362428.0938 - accuracy: 0.3412 - val_loss: -620141.8750 - val_accuracy: 0.2439\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -531298.0625 - accuracy: 0.3622 - val_loss: -918093.2500 - val_accuracy: 0.2439\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -755529.7500 - accuracy: 0.3570 - val_loss: -1122401.5000 - val_accuracy: 0.2439\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -988413.6250 - accuracy: 0.2651 - val_loss: -1672808.2500 - val_accuracy: 0.5610\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -1535994.7500 - accuracy: 0.3360 - val_loss: -2238178.7500 - val_accuracy: 0.2439\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -1931994.7500 - accuracy: 0.2546 - val_loss: -2839124.0000 - val_accuracy: 0.5488\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -2812865.7500 - accuracy: 0.3438 - val_loss: -3785492.2500 - val_accuracy: 0.2439\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 1s 60ms/step - loss: -3376776.5000 - accuracy: 0.3281 - val_loss: -5067773.0000 - val_accuracy: 0.5244\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -4334337.5000 - accuracy: 0.3438 - val_loss: -6333508.5000 - val_accuracy: 0.2439\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -5837686.5000 - accuracy: 0.3123 - val_loss: -8065245.0000 - val_accuracy: 0.2439\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -7374705.5000 - accuracy: 0.3648 - val_loss: -10062329.0000 - val_accuracy: 0.2439\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 1s 69ms/step - loss: -9325313.0000 - accuracy: 0.4094 - val_loss: -12165264.0000 - val_accuracy: 0.5366\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -10838210.0000 - accuracy: 0.3753 - val_loss: -15122902.0000 - val_accuracy: 0.4268\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -13451734.0000 - accuracy: 0.4646 - val_loss: -17869178.0000 - val_accuracy: 0.5244\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 1s 67ms/step - loss: -16153587.0000 - accuracy: 0.3517 - val_loss: -22730746.0000 - val_accuracy: 0.5366\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 1s 66ms/step - loss: -20673756.0000 - accuracy: 0.3806 - val_loss: -26582808.0000 - val_accuracy: 0.5366\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: -24133998.0000 - accuracy: 0.3701 - val_loss: -32438190.0000 - val_accuracy: 0.2439\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -27980712.0000 - accuracy: 0.3465 - val_loss: -38198364.0000 - val_accuracy: 0.2439\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -34469004.0000 - accuracy: 0.3622 - val_loss: -44571344.0000 - val_accuracy: 0.5488\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -41810364.0000 - accuracy: 0.4409 - val_loss: -52994560.0000 - val_accuracy: 0.5244\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -44791120.0000 - accuracy: 0.3832 - val_loss: -62885908.0000 - val_accuracy: 0.2317\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -53875652.0000 - accuracy: 0.3990 - val_loss: -71930768.0000 - val_accuracy: 0.2439\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -63068704.0000 - accuracy: 0.4567 - val_loss: -84100120.0000 - val_accuracy: 0.5244\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -75137440.0000 - accuracy: 0.4646 - val_loss: -94945840.0000 - val_accuracy: 0.5244\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -82272392.0000 - accuracy: 0.3570 - val_loss: -107582464.0000 - val_accuracy: 0.5488\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -99840104.0000 - accuracy: 0.4751 - val_loss: -126338144.0000 - val_accuracy: 0.5366\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -107251560.0000 - accuracy: 0.4567 - val_loss: -140440192.0000 - val_accuracy: 0.5366\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -125052528.0000 - accuracy: 0.4304 - val_loss: -159150624.0000 - val_accuracy: 0.5244\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -134868416.0000 - accuracy: 0.4672 - val_loss: -177087984.0000 - val_accuracy: 0.5488\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -153534768.0000 - accuracy: 0.4698 - val_loss: -202293792.0000 - val_accuracy: 0.5366\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 1s 60ms/step - loss: -175610912.0000 - accuracy: 0.3596 - val_loss: -227052240.0000 - val_accuracy: 0.5366\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 50ms/step - loss: -186969376.0000 - accuracy: 0.4409 - val_loss: -255895776.0000 - val_accuracy: 0.2561\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 1s 47ms/step - loss: -207201184.0000 - accuracy: 0.3596 - val_loss: -284816768.0000 - val_accuracy: 0.5244\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -252884832.0000 - accuracy: 0.4646 - val_loss: -314787680.0000 - val_accuracy: 0.5488\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -259339280.0000 - accuracy: 0.4488 - val_loss: -343681184.0000 - val_accuracy: 0.5488\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -291006208.0000 - accuracy: 0.4882 - val_loss: -377834784.0000 - val_accuracy: 0.5488\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: -330803488.0000 - accuracy: 0.4777 - val_loss: -414080192.0000 - val_accuracy: 0.5366\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -336144832.0000 - accuracy: 0.4698 - val_loss: -446536928.0000 - val_accuracy: 0.5366\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -379690176.0000 - accuracy: 0.4803 - val_loss: -493808416.0000 - val_accuracy: 0.5366\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -429032064.0000 - accuracy: 0.4619 - val_loss: -531006784.0000 - val_accuracy: 0.5244\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 1s 60ms/step - loss: -479348224.0000 - accuracy: 0.4698 - val_loss: -585659328.0000 - val_accuracy: 0.5244\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -498006848.0000 - accuracy: 0.4278 - val_loss: -644412096.0000 - val_accuracy: 0.5366\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -560702912.0000 - accuracy: 0.4724 - val_loss: -697419520.0000 - val_accuracy: 0.5366\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -593708800.0000 - accuracy: 0.4541 - val_loss: -764524864.0000 - val_accuracy: 0.5244\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -616685056.0000 - accuracy: 0.4567 - val_loss: -827520384.0000 - val_accuracy: 0.5244\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: -722167040.0000 - accuracy: 0.4619 - val_loss: -888735872.0000 - val_accuracy: 0.5244\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -796058560.0000 - accuracy: 0.4331 - val_loss: -966028928.0000 - val_accuracy: 0.5244\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -805566336.0000 - accuracy: 0.4672 - val_loss: -1036076224.0000 - val_accuracy: 0.5122\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -818656128.0000 - accuracy: 0.4698 - val_loss: -1138223616.0000 - val_accuracy: 0.5366\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -962898176.0000 - accuracy: 0.4803 - val_loss: -1199394560.0000 - val_accuracy: 0.5366\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -1040694592.0000 - accuracy: 0.4856 - val_loss: -1288861184.0000 - val_accuracy: 0.5244\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: -1121889152.0000 - accuracy: 0.4646 - val_loss: -1381309312.0000 - val_accuracy: 0.5244\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: -1159227392.0000 - accuracy: 0.4593 - val_loss: -1507009920.0000 - val_accuracy: 0.5244\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -1277339904.0000 - accuracy: 0.4751 - val_loss: -1620405888.0000 - val_accuracy: 0.5366\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -1294112384.0000 - accuracy: 0.4777 - val_loss: -1713415552.0000 - val_accuracy: 0.5366\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -1449412736.0000 - accuracy: 0.4908 - val_loss: -1815628544.0000 - val_accuracy: 0.5488\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -1448806784.0000 - accuracy: 0.4934 - val_loss: -1939394432.0000 - val_accuracy: 0.5366\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 1s 60ms/step - loss: -1662187904.0000 - accuracy: 0.4751 - val_loss: -2062749952.0000 - val_accuracy: 0.5366\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -1781502592.0000 - accuracy: 0.4226 - val_loss: -2185876224.0000 - val_accuracy: 0.5366\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 1s 61ms/step - loss: -1892633984.0000 - accuracy: 0.4462 - val_loss: -2301652736.0000 - val_accuracy: 0.5366\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 1s 60ms/step - loss: -2038609280.0000 - accuracy: 0.4751 - val_loss: -2468248320.0000 - val_accuracy: 0.5366\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -2187649536.0000 - accuracy: 0.4541 - val_loss: -2613188352.0000 - val_accuracy: 0.5244\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 1s 66ms/step - loss: -2171163392.0000 - accuracy: 0.4829 - val_loss: -2751421184.0000 - val_accuracy: 0.5488\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 1s 63ms/step - loss: -2404129280.0000 - accuracy: 0.4619 - val_loss: -2928660480.0000 - val_accuracy: 0.5244\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -2602825216.0000 - accuracy: 0.4698 - val_loss: -3111812352.0000 - val_accuracy: 0.5244\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -2695687424.0000 - accuracy: 0.4488 - val_loss: -3305031168.0000 - val_accuracy: 0.5244\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -2855981312.0000 - accuracy: 0.4567 - val_loss: -3509528320.0000 - val_accuracy: 0.5366\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -3081228288.0000 - accuracy: 0.4646 - val_loss: -3729327360.0000 - val_accuracy: 0.5244\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 1s 63ms/step - loss: -3081085440.0000 - accuracy: 0.4856 - val_loss: -3931518208.0000 - val_accuracy: 0.5244\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -3609484800.0000 - accuracy: 0.4698 - val_loss: -4100224000.0000 - val_accuracy: 0.2439\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 1s 71ms/step - loss: -3747424512.0000 - accuracy: 0.4829 - val_loss: -4357305344.0000 - val_accuracy: 0.5244\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 1s 61ms/step - loss: -3745896448.0000 - accuracy: 0.4619 - val_loss: -4619256832.0000 - val_accuracy: 0.5244\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: -4080363520.0000 - accuracy: 0.4593 - val_loss: -4849714688.0000 - val_accuracy: 0.5244\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -4158182400.0000 - accuracy: 0.4777 - val_loss: -5115874304.0000 - val_accuracy: 0.5366\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -4309405184.0000 - accuracy: 0.4514 - val_loss: -5441843200.0000 - val_accuracy: 0.5366\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 1s 69ms/step - loss: -4653912064.0000 - accuracy: 0.4619 - val_loss: -5740975104.0000 - val_accuracy: 0.5366\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -4916956672.0000 - accuracy: 0.4724 - val_loss: -5975458816.0000 - val_accuracy: 0.5366\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -4913634304.0000 - accuracy: 0.4803 - val_loss: -6292651008.0000 - val_accuracy: 0.5366\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -5739798528.0000 - accuracy: 0.4803 - val_loss: -6579516928.0000 - val_accuracy: 0.5244\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -5669457920.0000 - accuracy: 0.4856 - val_loss: -6802670592.0000 - val_accuracy: 0.5488\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -5812444672.0000 - accuracy: 0.4698 - val_loss: -7210767872.0000 - val_accuracy: 0.5244\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 54ms/step - loss: -6003674112.0000 - accuracy: 0.4698 - val_loss: -7575287808.0000 - val_accuracy: 0.5244\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -6435799552.0000 - accuracy: 0.4698 - val_loss: -7891194368.0000 - val_accuracy: 0.5244\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -6874303488.0000 - accuracy: 0.4803 - val_loss: -8286521856.0000 - val_accuracy: 0.5366\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -6759669248.0000 - accuracy: 0.4829 - val_loss: -8630757376.0000 - val_accuracy: 0.5244\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -7194457600.0000 - accuracy: 0.4751 - val_loss: -8983540736.0000 - val_accuracy: 0.5244\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -7624855040.0000 - accuracy: 0.4724 - val_loss: -9403865088.0000 - val_accuracy: 0.5366\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -7376537600.0000 - accuracy: 0.4751 - val_loss: -9842259968.0000 - val_accuracy: 0.5244\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -8376615424.0000 - accuracy: 0.4724 - val_loss: -10316717056.0000 - val_accuracy: 0.5366\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -8741735424.0000 - accuracy: 0.4724 - val_loss: -10721994752.0000 - val_accuracy: 0.5244\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 1s 61ms/step - loss: -9225682944.0000 - accuracy: 0.4829 - val_loss: -11141508096.0000 - val_accuracy: 0.5366\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -9308732416.0000 - accuracy: 0.4724 - val_loss: -11645967360.0000 - val_accuracy: 0.5366\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -9888631808.0000 - accuracy: 0.4672 - val_loss: -12130198528.0000 - val_accuracy: 0.5366\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -10002862080.0000 - accuracy: 0.4724 - val_loss: -12609547264.0000 - val_accuracy: 0.5366\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -10861125632.0000 - accuracy: 0.4803 - val_loss: -13028513792.0000 - val_accuracy: 0.5488\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: -10803451904.0000 - accuracy: 0.4803 - val_loss: -13647681536.0000 - val_accuracy: 0.5244\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -11518407680.0000 - accuracy: 0.4777 - val_loss: -14213092352.0000 - val_accuracy: 0.5244\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -12464924672.0000 - accuracy: 0.4724 - val_loss: -14802399232.0000 - val_accuracy: 0.5244\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -12947348480.0000 - accuracy: 0.4751 - val_loss: -15317751808.0000 - val_accuracy: 0.5488\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -12919071744.0000 - accuracy: 0.4829 - val_loss: -15902911488.0000 - val_accuracy: 0.5244\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: -13919182848.0000 - accuracy: 0.4751 - val_loss: -16524696576.0000 - val_accuracy: 0.5244\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -14083749888.0000 - accuracy: 0.4646 - val_loss: -17339541504.0000 - val_accuracy: 0.5244\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -14606744576.0000 - accuracy: 0.4751 - val_loss: -17991737344.0000 - val_accuracy: 0.5244\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 1s 51ms/step - loss: -15833696256.0000 - accuracy: 0.4803 - val_loss: -18711916544.0000 - val_accuracy: 0.5366\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -15730050048.0000 - accuracy: 0.4803 - val_loss: -19397562368.0000 - val_accuracy: 0.5244\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 1s 61ms/step - loss: -16765940736.0000 - accuracy: 0.4829 - val_loss: -20265914368.0000 - val_accuracy: 0.2439\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: -17680726016.0000 - accuracy: 0.4409 - val_loss: -20988737536.0000 - val_accuracy: 0.5366\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: -18568677376.0000 - accuracy: 0.4619 - val_loss: -21658515456.0000 - val_accuracy: 0.5244\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: -18446872576.0000 - accuracy: 0.4724 - val_loss: -22639036416.0000 - val_accuracy: 0.5244\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 1s 66ms/step - loss: -18508136448.0000 - accuracy: 0.4646 - val_loss: -23594813440.0000 - val_accuracy: 0.5244\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -20907358208.0000 - accuracy: 0.4803 - val_loss: -24352886784.0000 - val_accuracy: 0.5366\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -20788758528.0000 - accuracy: 0.4698 - val_loss: -25109450752.0000 - val_accuracy: 0.5366\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: -22224539648.0000 - accuracy: 0.4803 - val_loss: -25849208832.0000 - val_accuracy: 0.5244\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 1s 66ms/step - loss: -21541476352.0000 - accuracy: 0.4751 - val_loss: -26863013888.0000 - val_accuracy: 0.5244\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: -23374962688.0000 - accuracy: 0.4751 - val_loss: -28049532928.0000 - val_accuracy: 0.5244\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -24646506496.0000 - accuracy: 0.4829 - val_loss: -29103288320.0000 - val_accuracy: 0.5244\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -24375934976.0000 - accuracy: 0.4777 - val_loss: -30077894656.0000 - val_accuracy: 0.5244\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -24891258880.0000 - accuracy: 0.4672 - val_loss: -31089098752.0000 - val_accuracy: 0.5366\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: -27630825472.0000 - accuracy: 0.4751 - val_loss: -32200982528.0000 - val_accuracy: 0.5244\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -27278688256.0000 - accuracy: 0.4751 - val_loss: -33104240640.0000 - val_accuracy: 0.5366\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -29093261312.0000 - accuracy: 0.4751 - val_loss: -34419949568.0000 - val_accuracy: 0.5244\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 1s 68ms/step - loss: -30110898176.0000 - accuracy: 0.4751 - val_loss: -35606257664.0000 - val_accuracy: 0.5366\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 1s 72ms/step - loss: -31124307968.0000 - accuracy: 0.4829 - val_loss: -36687646720.0000 - val_accuracy: 0.5366\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -31202246656.0000 - accuracy: 0.4829 - val_loss: -37867565056.0000 - val_accuracy: 0.5488\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 1s 71ms/step - loss: -31853058048.0000 - accuracy: 0.4803 - val_loss: -39053553664.0000 - val_accuracy: 0.5488\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -34090375168.0000 - accuracy: 0.4751 - val_loss: -40075931648.0000 - val_accuracy: 0.5244\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -36545597440.0000 - accuracy: 0.4646 - val_loss: -41573949440.0000 - val_accuracy: 0.5366\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: -34429718528.0000 - accuracy: 0.4646 - val_loss: -42998689792.0000 - val_accuracy: 0.5244\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -37382311936.0000 - accuracy: 0.4672 - val_loss: -44285419520.0000 - val_accuracy: 0.5244\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 1s 61ms/step - loss: -38157885440.0000 - accuracy: 0.4777 - val_loss: -45891944448.0000 - val_accuracy: 0.5244\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 76ms/step - loss: -39585796096.0000 - accuracy: 0.4724 - val_loss: -47441772544.0000 - val_accuracy: 0.5244\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 1s 67ms/step - loss: -42876530688.0000 - accuracy: 0.4646 - val_loss: -48861929472.0000 - val_accuracy: 0.5366\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -44378988544.0000 - accuracy: 0.4777 - val_loss: -50421436416.0000 - val_accuracy: 0.5244\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -43075915776.0000 - accuracy: 0.4777 - val_loss: -51896680448.0000 - val_accuracy: 0.5244\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -43865624576.0000 - accuracy: 0.4619 - val_loss: -53623549952.0000 - val_accuracy: 0.5244\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: -45551169536.0000 - accuracy: 0.4672 - val_loss: -55421345792.0000 - val_accuracy: 0.5244\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -49243471872.0000 - accuracy: 0.4856 - val_loss: -57026600960.0000 - val_accuracy: 0.5366\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -48496181248.0000 - accuracy: 0.4777 - val_loss: -58924785664.0000 - val_accuracy: 0.5366\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -51852783616.0000 - accuracy: 0.4777 - val_loss: -60551426048.0000 - val_accuracy: 0.5244\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -49315663872.0000 - accuracy: 0.4803 - val_loss: -62254219264.0000 - val_accuracy: 0.5244\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: -53076377600.0000 - accuracy: 0.4751 - val_loss: -63758856192.0000 - val_accuracy: 0.5244\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -56465342464.0000 - accuracy: 0.4593 - val_loss: -65839497216.0000 - val_accuracy: 0.5244\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: -57004486656.0000 - accuracy: 0.4541 - val_loss: -67817746432.0000 - val_accuracy: 0.5244\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 1s 59ms/step - loss: -58574413824.0000 - accuracy: 0.4803 - val_loss: -69571305472.0000 - val_accuracy: 0.5244\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 1s 47ms/step - loss: -58187821056.0000 - accuracy: 0.4829 - val_loss: -71621623808.0000 - val_accuracy: 0.5244\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 1s 65ms/step - loss: -61779611648.0000 - accuracy: 0.4724 - val_loss: -73645096960.0000 - val_accuracy: 0.5244\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -62522150912.0000 - accuracy: 0.4751 - val_loss: -75607793664.0000 - val_accuracy: 0.5244\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 1s 62ms/step - loss: -65763934208.0000 - accuracy: 0.4672 - val_loss: -77617709056.0000 - val_accuracy: 0.5244\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 1s 71ms/step - loss: -67261603840.0000 - accuracy: 0.4698 - val_loss: -80148955136.0000 - val_accuracy: 0.5244\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 1s 63ms/step - loss: -68324380672.0000 - accuracy: 0.4698 - val_loss: -82016886784.0000 - val_accuracy: 0.5366\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -72983281664.0000 - accuracy: 0.4803 - val_loss: -84273602560.0000 - val_accuracy: 0.5244\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -71962812416.0000 - accuracy: 0.4698 - val_loss: -86392733696.0000 - val_accuracy: 0.5244\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 1s 67ms/step - loss: -72142659584.0000 - accuracy: 0.4646 - val_loss: -89702309888.0000 - val_accuracy: 0.5244\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -78302601216.0000 - accuracy: 0.4751 - val_loss: -91884568576.0000 - val_accuracy: 0.5244\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -77576159232.0000 - accuracy: 0.4777 - val_loss: -94010826752.0000 - val_accuracy: 0.5366\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 1s 57ms/step - loss: -77161897984.0000 - accuracy: 0.4751 - val_loss: -96441540608.0000 - val_accuracy: 0.5366\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -80492535808.0000 - accuracy: 0.4724 - val_loss: -98596716544.0000 - val_accuracy: 0.5488\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 1s 47ms/step - loss: -82767003648.0000 - accuracy: 0.4751 - val_loss: -100718084096.0000 - val_accuracy: 0.5488\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -88364146688.0000 - accuracy: 0.4934 - val_loss: -103680032768.0000 - val_accuracy: 0.5244\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -90423549952.0000 - accuracy: 0.4698 - val_loss: -106153500672.0000 - val_accuracy: 0.5244\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -93204226048.0000 - accuracy: 0.4751 - val_loss: -109023477760.0000 - val_accuracy: 0.5244\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -87461765120.0000 - accuracy: 0.4777 - val_loss: -111487770624.0000 - val_accuracy: 0.5244\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: -93370482688.0000 - accuracy: 0.4698 - val_loss: -114551611392.0000 - val_accuracy: 0.5244\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 1s 49ms/step - loss: -96410624000.0000 - accuracy: 0.4829 - val_loss: -117494816768.0000 - val_accuracy: 0.5244\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: -101883518976.0000 - accuracy: 0.4803 - val_loss: -120408621056.0000 - val_accuracy: 0.5244\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: -105441845248.0000 - accuracy: 0.4777 - val_loss: -123611922432.0000 - val_accuracy: 0.5244\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 1s 43ms/step - loss: -103608688640.0000 - accuracy: 0.4751 - val_loss: -126463787008.0000 - val_accuracy: 0.5366\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -110160642048.0000 - accuracy: 0.4724 - val_loss: -128927686656.0000 - val_accuracy: 0.5366\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 1s 46ms/step - loss: -110235041792.0000 - accuracy: 0.4803 - val_loss: -131954720768.0000 - val_accuracy: 0.5244\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: -112972808192.0000 - accuracy: 0.4698 - val_loss: -135186186240.0000 - val_accuracy: 0.5244\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -114793275392.0000 - accuracy: 0.4751 - val_loss: -137958129664.0000 - val_accuracy: 0.5366\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 1s 54ms/step - loss: -117917196288.0000 - accuracy: 0.4751 - val_loss: -141341655040.0000 - val_accuracy: 0.5244\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 1s 64ms/step - loss: -119234330624.0000 - accuracy: 0.4593 - val_loss: -145134911488.0000 - val_accuracy: 0.5244\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -124736225280.0000 - accuracy: 0.4619 - val_loss: -148217233408.0000 - val_accuracy: 0.5244\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 1s 55ms/step - loss: -130530713600.0000 - accuracy: 0.4698 - val_loss: -151260413952.0000 - val_accuracy: 0.5244\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 1s 56ms/step - loss: -133684379648.0000 - accuracy: 0.4724 - val_loss: -154964967424.0000 - val_accuracy: 0.5244\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: -131048374272.0000 - accuracy: 0.4698 - val_loss: -158737580032.0000 - val_accuracy: 0.5244\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: -137867509760.0000 - accuracy: 0.4724 - val_loss: -162003763200.0000 - val_accuracy: 0.5244\n"
     ]
    }
   ],
   "source": [
    "model_2layer.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "hist_2layer = model_2layer.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=200,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
